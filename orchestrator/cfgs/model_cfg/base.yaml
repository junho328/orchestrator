model_log_name: base_model
model_name_or_path: Qwen/Qwen2.5-7B-Instruct
tokenizer_name_or_path: ${model_name_or_path}

use_peft: true
load_in_4bit: true

lora_r: 16
lora_alpha: 32
lora_dropout: 0.0
lora_target_modules: all-linear 
lora_modules_to_save: all-linear
lora_task_type: "CAUSAL_LM"
use_rslora: false
bnb_4bit_quant_type: "nf4"
use_bnb_nested_quant: false

model_args:
  _target_: trl.trainer.model_config.ModelConfig
  model_name_or_path: ${model_name_or_path}
  trust_remote_code: true
  use_peft: ${use_peft}
  load_in_4bit: ${load_in_4bit}
  lora_r: ${lora_r}
  lora_alpha: ${lora_alpha}
  lora_dropout: ${lora_dropout}
  lora_target_modules: ${lora_target_modules}
  lora_modules_to_save: ${lora_modules_to_save}
  lora_task_type: ${lora_task_type}
  use_rslora: ${use_rslora}
  bnb_4bit_quant_type: ${bnb_4bit_quant_type}
  use_bnb_nested_quant: ${use_bnb_nested_quant}

tokenizer:
  _target_: transformers.AutoTokenizer.from_pretrained
  pretrained_model_name_or_path: ${tokenizer_name_or_path}
  trust_remote_code: true

make_tokenizer_fn:
  _target_: orchestrator.hydra_utils.fix_pad_token
  tokenizer: ${tokenizer}
  model_name: ${model_name_or_path}

peft_config:
  _target_: trl.trainer.utils.get_peft_config
  model_args: ${model_args}

