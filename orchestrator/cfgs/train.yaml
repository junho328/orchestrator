defaults:
  - _self_
  - model_cfg@_global_: base
  - data_cfg@_global_: bigcodebench
  - trainer_cfg@_global_: grpo
  - run_cfg@_global_: default

# Default settings for orchestrator training

# saving:
save_strategy: epoch
save_steps: 1
push_to_hub: false

per_device_train_batch_size: 4

# logging:
logging_strategy: steps
logging_steps: 1
report_to: "wandb"
wandb_project: orchestrator
wandb_group_name: lamas-aipr
wandb_run_name: ${model_log_name}_${data_log_name}_${trainer_log_name}

# dirs:
results_dir: /ext_hdd/jhna/marllm
exp_name: ${now:%Y.%m.%d}${now:%H%M%S}
output_dir: ${results_dir}/${wandb_run_name}/${exp_name}

# resume/eval:
resume_from:
evaluate_only: false
save_final_model: true

seed: 42

hydra:
  run:
    dir: ${output_dir}

