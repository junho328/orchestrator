defaults:
  - _self_

seed: 42

b200_models:
  - "google/gemma-3-27b-it"
  - "meta-llama/Llama-3.1-8B-Instruct"
  - "Qwen/Qwen2.5-32B-Instruct"
  - "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B"

available_models_id: 
  - "google/gemma-3-27b-it"
  - "Qwen/Qwen2.5-32B-Instruct"
  - "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B"

open_ports:
  google/gemma-3-27b-it: 8322
  Qwen/Qwen2.5-32B-Instruct: 8324
  deepseek-ai/DeepSeek-R1-Distill-Qwen-32B: 8325

servers:
  google/gemma-3-27b-it: localhost
  Qwen/Qwen2.5-32B-Instruct: localhost
  deepseek-ai/DeepSeek-R1-Distill-Qwen-32B: localhost

# data
dataset_split: train
available_models: ${b200_models}          
max_routing_steps: 5
data_limit: 1000    
dataset_id_or_path: Jiayi-Pan/Countdown-Tasks-3to4
dataset_prompt_style: reproduce 

data_log_name: countdown_coldstart_${dataset_prompt_style}_${data_limit}

# llm call
llm_provider: deepseek
llm_model: deepseek-chat
temperature: 0.7
max_tokens: 1024

# output
output_dir: data/router_demos/${llm_provider}/${llm_model}
output_file: ${output_dir}/${dataset_id_or_path}/${now:%Y%m%d_%H%M%S}.jsonl

# Hydra bookkeeping
hydra:
  run:
    dir: ${output_dir}